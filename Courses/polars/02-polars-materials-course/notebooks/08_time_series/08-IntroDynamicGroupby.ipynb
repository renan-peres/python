{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057fc15a-eecc-407a-96f8-13398032c721",
   "metadata": {},
   "source": [
    "# Introduction to `group_by_dynamic`\n",
    "By the end of this session you will be able to:\n",
    "\n",
    "- do temporal aggregations using `group_by_dynamic`\n",
    "- understand the role of sorting in `group_by_dynamic`\n",
    "- use `group_by_dynamic` in lazy mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30707ebc-2b0e-4cfb-baff-ab17c65d83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfcd8c-6bbe-49b2-ac7f-f0a63d92837b",
   "metadata": {},
   "source": [
    "We use the time series of NYC taxi pickups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091db89e-459c-43e4-8431-e86dffeabdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/nyc_trip_data_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b84e9d-363c-4099-a70f-d323e8cc46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file,try_parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944f6f5-b122-4719-ac42-b3d668b78dad",
   "metadata": {},
   "source": [
    "## Temporal aggregation with datetime components and `group_by`\n",
    "The simplest way to do a temporal aggregation on a time series is to:\n",
    "- create the datetime components of interest\n",
    "- do a `group_by` on these components\n",
    "- `sort` the output back into time series order\n",
    "\n",
    "In this example we get the average trip distance by date (using `dt.date` to cast the `pl.Datetime` to `pl.Date`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b80659-e8d1-41ed-81bf-54635b50b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .group_by(\n",
    "        pl.col(\"pickup\").dt.date().alias(\"date\")\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").mean().round(1),\n",
    "    )\n",
    "    .sort(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a9c49-7459-4a90-afdd-5d0442a8e363",
   "metadata": {},
   "source": [
    "This approach with `group_by` works well if we can easily transform our `pl.Datetime/pl.Date` column to the time window we want to use. In this example we can easily use `dt.date` to transform the `pl.Datetimes` to the daily time window. However, this approach becomes more challenging when we want more complicated time windows. For example, during my PhD at Oxford as an [oceanography scientist](https://scholar.google.co.uk/citations?user=43HnNKAAAAAJ&hl=en) I sometimes had to calculate averages over a tidal period of 12 hours 25.2 minutes!\n",
    "\n",
    "> At present we cannot use the `group_by_dynamic` approach we see below for streaming queries so it is good to remember this approach using `group_by` as a backup for these cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665936b0-50f9-4e77-8efa-16b2342dbd46",
   "metadata": {},
   "source": [
    "## Temporal groupby with `group_by_dynamic`\n",
    "With `group_by_dynamic` we can do grouping based on time windows. With this approach:\n",
    "- Polars takes the input parameters to create time window boundaries\n",
    "- Polars then finds all the rows that correspond to each window\n",
    "\n",
    "### Sorted data for `group_by_dynamic`\n",
    "One area that can be confusing with `group_by_dynamic` can be the requirements around sortedness.\n",
    "\n",
    "**For `group_by_dynamic` the date/datetime column must be sorted in ascending order**. Sortedness is required because in the second step of finding all the rows that correspond to each window Polars uses a fast-track algorithm that requires sorted data.\n",
    "\n",
    "Note that the date/datetime column we are using for the windows is called the *index* column in `group_by_dynamic`.\n",
    "\n",
    "To ensure that index column is sorted we need to either:\n",
    "- sort the index column with `sort` (slower but less risky)\n",
    "- use `set_sorted` on the index column if we know the column is already sorted\n",
    "\n",
    "To check sortedness we can use `is_sorted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52fad0-bac6-4272-95ca-ba8f1a7f2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pickup\"].is_sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577fa63-3311-4b6e-8dea-ecd62288d849",
   "metadata": {},
   "source": [
    "The `is_sorted` method scans the full column to check sortedness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b31fac-b33c-466b-8214-e5ddd9edb52a",
   "metadata": {},
   "source": [
    "As the output is `True` we can use `set_sorted`.\n",
    "\n",
    "> In my own time series pipelines I normally do an explicit `sort` before doing `group_by_dynamic` to avoid hard-to-detect errors creeping in if the data is unexpectedly unsorted.\n",
    "\n",
    "### Syntax\n",
    "In its simplest form the arguments to `group_by_dynamic` are:\n",
    "- the datetime `index` column to create windows on and \n",
    "- the temporal length of the windows with the `every` argument as an interval string\n",
    "\n",
    "Here we create windows of one day's length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d53811-b59e-4da4-976a-2a748805b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\n",
    "        \"pickup\", \n",
    "        every=\"1d\"\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").mean().round(1)\n",
    "    )\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9dd83-387f-430d-8db0-a688c2993774",
   "metadata": {},
   "source": [
    "We look at how the windows are specified in more detail in the next lecture\n",
    "\n",
    "What happens if we don't do `set_sorted` (or `sort`)? Uncomment this code to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ac92e-3876-44ef-a7e3-d8bc055e6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     df\n",
    "#     .group_by_dynamic(\n",
    "#         \"pickup\", \n",
    "#         every=\"1d\"\n",
    "#     )\n",
    "#     .agg(\n",
    "#         pl.col(\"trip_distance\").mean().round(1)\n",
    "#     )\n",
    "#     .head(5)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340bb57-a64e-4a58-ac03-b3f12169cf15",
   "metadata": {},
   "source": [
    "Polars returns an exception with some advice about how we can tell it that the `index` column is sorted.\n",
    "\n",
    "### More sorting\n",
    "There is a `check_sorted` argument to `group_by_dynamic` that is `True` by default. When this argument is `True` Polars checks if the `index` column is sorted. However, this `check_sorted` operation **only checks the `flags` attribute of the `index` column**, it does not scan the data in the column to check if it is sorted. \n",
    "\n",
    "So when `check_sorted=True` (the default) Polars:\n",
    "- checks the flag attribute of the `index` column\n",
    "    - if the `index` column has `'SORTED_ASC': True` then Polars does `group_by_dynamic`\n",
    "    - if the `index` column has `'SORTED_ASC': False` then Polars raises an `Exception` (as above)\n",
    " \n",
    "When `check_sorted=False` Polars:\n",
    "- does `group_by_dynamic` and potentially produces incorrect results if the `index` column is not actually sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a79bc-0d46-462a-b623-97266ce28add",
   "metadata": {},
   "source": [
    "## `DynamicGroupBy` object\n",
    "\n",
    "When we do `group_by_dynamic` we create a `DynamicGroupBy` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7fea6-5292-4510-89fb-8b7281e3791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\n",
    "        \"pickup\", \n",
    "        every=\"1d\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8686486-4d79-4684-9199-8958c74f2ef5",
   "metadata": {},
   "source": [
    "To do aggregations on a `DynamicGroupBy` we call `agg`. We cannot call aggregation methods like `count` or `sum` on a `DynamicGroupBy` directly.\n",
    "\n",
    "## Dynamic groupby on groups\n",
    "We may want to divide the `DataFrame` into groups before doing `group_by_dynamic` on each group. For example in the taxi data we may want to get the daily average tip by driver.\n",
    "\n",
    "We can do this grouping with the `group_by` argument in `group_by_dynamic`.\n",
    "\n",
    "To illustrate this we groupby each `VendorID` and then take hourly averages of the `trip_distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192a341-e465-4c63-9f84-cc6b25828336",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .sort(\"VendorID\",\"pickup\")\n",
    "    .group_by_dynamic(\"pickup\",every=\"3h\",group_by=\"VendorID\")\n",
    "    .agg(\n",
    "        pl.col(\"tip_amount\").mean().round(1)\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94aa09-8873-40cc-bc5d-c8893fffe295",
   "metadata": {},
   "source": [
    "Notice the order of the columns - Polars first groups by `VendorID` and then does `group_by_dynamic` on each of those groups.\n",
    "\n",
    "We can also use expressions when grouping by another column - see the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f26735-221b-41ee-bc2e-052b3600ef21",
   "metadata": {},
   "source": [
    "## Dynamic groupby in lazy mode\n",
    "When we do `group_by_dynamic` the Polars query optimiser sees that only a subset of columns are required and only reads these columns from the CSV (`PROJECT 3/7 COLUMNS` below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedea2c-d188-4cee-a398-5154eab1821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    pl.scan_csv(csv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\"pickup\",every=\"3h\",group_by=\"passenger_count\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").mean().round(1)\n",
    "    )\n",
    "    .explain()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339016a-d2f4-4380-a54a-728253f1a1c8",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- doing `group_by_dynamic` on a single column\n",
    "- doing `group_by_dynamic` on groups\n",
    "- the relative performance of `group_by_dynamic` and `groupby`\n",
    "\n",
    "### Exercise 1\n",
    "Groupby the `pickup` column on a 6-hourly basis.\n",
    "\n",
    "Get the count, mean and max of the trip distance for each window.\n",
    "\n",
    "Sort the output by the mean trip distance with the largest values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dee86e-f408-4e35-868a-6afb3385d73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8e8113-d41d-49e9-91a6-aa424f7dd6dc",
   "metadata": {},
   "source": [
    "Filter out all windows with less than 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93f54d-1393-4028-abdd-9debeef2dea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb7ea2e8-5539-4a82-8014-8919f32ea223",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Get the same statistics but also group by the Vendor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91ffdf-8165-41a8-a7ea-4f3ef5f9198a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee1cbfd-9148-4a4d-9bd2-7f51ddfca407",
   "metadata": {},
   "source": [
    "Get the same statistics (`count`,`max` and `mean`) but group by both:\n",
    "- the Vendor ID and \n",
    "- the `trip_distance` where the `trip_distance` is cast to a 16-bit integer before grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d77e44-f71d-479a-ba4a-6cbbb5d23a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "744ce7f2-e4f8-4421-b617-91bf67bc82ed",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to exercise 1\n",
    "Groupby the `pickup` column on a 6-hourly basis.\n",
    "\n",
    "Get the count, mean and max of the trip distance for each window.\n",
    "\n",
    "Sort the output by the mean trip distance with the largest values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a58d27-f922-40c2-9ae3-d76a61ed6a28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\"pickup\",every=\"6h\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").count().alias(\"count\"),\n",
    "        pl.col(\"trip_distance\").mean().alias(\"mean\"),\n",
    "        pl.col(\"trip_distance\").max().alias(\"max\"),\n",
    "    )\n",
    "    .sort(\"mean\",descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4119c-e58d-4d86-a8f1-1fe5cb04917c",
   "metadata": {},
   "source": [
    "Filter out all windows with less than 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef59f78-4588-405f-884b-2528a9050ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\"pickup\",every=\"6h\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").count().alias(\"count\"),\n",
    "        pl.col(\"trip_distance\").mean().alias(\"mean\"),\n",
    "        pl.col(\"trip_distance\").max().alias(\"max\"),        \n",
    "    )\n",
    "    .filter(pl.col(\"count\") >= 5)\n",
    "    .sort(\"mean\",descending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952bb1f-fdb0-4e96-80bb-5177ee1ec9ec",
   "metadata": {},
   "source": [
    "### Solution to exercise 2\n",
    "\n",
    "Get the same statistics but also group by the Vendor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c8763-e7a9-404f-b262-17247721b5db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\"pickup\",every=\"6h\",group_by=\"VendorID\")\n",
    "    .agg(\n",
    "        pl.col(\"trip_distance\").count().alias(\"count\"),\n",
    "        pl.col(\"trip_distance\").mean().alias(\"mean\"),\n",
    "        pl.col(\"trip_distance\").max().alias(\"max\"),\n",
    "    )\n",
    "    .filter(pl.col(\"count\") >= 5)\n",
    "    .sort(\"mean\",descending=True)\n",
    "    .head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4cfd4-27b3-43d6-be24-d97d18b6ba8f",
   "metadata": {},
   "source": [
    "Get the same statistics (`count`,`max` and `mean`) but group by both:\n",
    "- the Vendor ID and \n",
    "- the `trip_distance` where the `trip_distance` is cast to a 16-bit integer before grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd2ec1-4688-41e8-b74d-2b95285b3e1f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.read_csv(csv_file,try_parse_dates=True)\n",
    "    .with_columns(\n",
    "        pl.col(\"pickup\").set_sorted()\n",
    "    )\n",
    "    .group_by_dynamic(\n",
    "        \"pickup\",\n",
    "        every=\"6h\",\n",
    "        group_by=[\n",
    "            \"VendorID\",\n",
    "            pl.col(\"trip_distance\").cast(pl.Int16())\n",
    "        ]\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"passenger_count\").count().alias(\"count\"),\n",
    "        pl.col(\"passenger_count\").mean().alias(\"mean\"),\n",
    "        pl.col(\"passenger_count\").max().alias(\"max\"),\n",
    "    )\n",
    "    .sort(\"mean\",descending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf90dad-dfef-4819-b65d-4815be60ec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343a2ee-19e4-4a91-9435-1e77acc828ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
