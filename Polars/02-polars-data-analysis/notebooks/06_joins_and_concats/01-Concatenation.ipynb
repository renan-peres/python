{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c668ee9-44db-428b-8114-681699d2bea6",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "By the end of this lecture you will be able to:\n",
    "- vertically concatenate `DataFrames`\n",
    "- handle inconsistent dtypes in a vertical concat\n",
    "- horizontally concatenate `DataFrames`\n",
    "- diagonally concatenate `DataFrames`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbcacc3-dc68-4544-a81d-4d7f2a9b877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1598ed-7f6e-40aa-97f4-90a673a82bad",
   "metadata": {},
   "source": [
    "We create a first `DataFrame` with fake trade records from 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c43a46-92fa-4183-9946-321e7807570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = pl.DataFrame(\n",
    "    [\n",
    "        {\"year\":2000,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":0},\n",
    "        {\"year\":2000,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":1},\n",
    "    ]\n",
    ")\n",
    "df_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5a9ff-a965-4621-82f0-23c03c6f118a",
   "metadata": {},
   "source": [
    "We now create a second `DataFrame` with trade records from 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a8976-199e-4ba6-8564-5a0746aefbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001 = pl.DataFrame(\n",
    "    [\n",
    "        {\"year\":2001,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":2},\n",
    "        {\"year\":2001,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":3},\n",
    "    ]\n",
    ")\n",
    "df_2001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7855fc-399e-493a-b23d-d581ab6ae445",
   "metadata": {},
   "source": [
    "## Combining `DataFrames` vertically\n",
    "If we have data in two different `DataFrames` that we combine as a new `DataFrame` we can manage the data in memory in three different ways:\n",
    "- keeping the data in the original two locations in memory and referencing the new `DataFrame` to these original locations\n",
    "- copying the data to a single location in memory and and referencing the new `DataFrame` to this single location\n",
    "- appending the data from the second `DataFrame` to the location of the first `DataFrame`\n",
    "\n",
    "We cover three methods for vertically combining `DataFrames`: `df.vstack`, `df.extend` and `pl.concat`. The output of each method is the same from a user perspective but differs in terms of where the data sits in memory underneath the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8f543-7b79-4918-997d-6742044bd98d",
   "metadata": {},
   "source": [
    "### `vstack`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80699fa5-e6c3-4b77-9d4d-6a2c12057e16",
   "metadata": {},
   "source": [
    "We combine the 2000 and 2001 `DataFrames` into a single `DataFrame` with the `vstack` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c92be-6ac7-4aa7-ab5f-6681141c213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_2000\n",
    "    .vstack(\n",
    "        df_2001\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdec5b1-ded6-4a35-9cf8-4dcb24fa0535",
   "metadata": {},
   "source": [
    "A `vstack`:\n",
    "- keeps the data from both `DataFrames` in their original locations in memory and points the new `DataFrame` to those locations\n",
    "\n",
    "### Rechunk\n",
    "A `vstack` is computationally very cheap (as no data is copied). However, subsequent operations (e.g. `group_by`) are slower than if the data has been *rechunked* (i.e. copied from the original two chunks to a new single location in memory.\n",
    "\n",
    "\n",
    "We can manually cause two `DataFrames` linked by `vstack` to be copied to a single location in memory with `rechunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c248742-8a04-4133-b090-ceba8b1e017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_2000\n",
    "    .vstack(\n",
    "        df_2001\n",
    "    )\n",
    "    .rechunk()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49659a4-ab5b-4ca1-99fc-a06384fb4a44",
   "metadata": {},
   "source": [
    "We see below that the `pl.concat` function is a way of applying `vstack` and `rechunk` to a list of `DataFrames`.\n",
    "\n",
    "### Extend\n",
    "We can append one `DataFrame` to another with `extend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc141e7-b739-4edd-bad1-1cdd570d49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_2000\n",
    "    .extend(\n",
    "        df_2001\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad373a-2295-42a0-895b-e73aead00950",
   "metadata": {},
   "source": [
    "An `extend`:\n",
    "- copies the data from second `DataFrame` (`df_2001`) and appends it to the data of the first `DataFrame` (`df_2000`)\n",
    "- modifies the first `DataFrame` (`df_2000`) *in-place*\n",
    "\n",
    "We can see that `df_2000` has been modified in-place as it now has both years of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d10fb-fd06-4054-b6e9-dd485cdfd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb433b15-8081-4f98-9986-02a29688d7e9",
   "metadata": {},
   "source": [
    "Before continuing we re-assign `df_2000` back to its original value to reduce confusion if cells are executed out-of-order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8f67f-44b5-4d1a-815b-85971fb6c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = pl.DataFrame(\n",
    "    [\n",
    "        {\"year\":2000,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":0},\n",
    "        {\"year\":2000,\"exporter\":\"India\",\"importer\":\"USA\",\"quantity\":1},\n",
    "    ]\n",
    ")\n",
    "df_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58189b54-0c26-4d63-816e-e7bd37c7f953",
   "metadata": {},
   "source": [
    "### Use case of `vstack`, `rechunk` and `extend`\n",
    "- If you are combining `DataFrames` to do more transformations/groupbys/joins etc it is normally best to use `vstack` and `rechunk` so that all the data is together in memory. In practice it is simpler to use `pl.concat` to do this as we see below\n",
    "- If you want to combine two `DataFrames` but do not want to do more operations on them (e.g. you just want to check their length of perhaps write to a file) you should use `vstack`\n",
    "- If you want to add a small `DataFrame` to a large `DataFrame` use `extend` as it only copies the data in the small `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c5b0c-4ef8-4364-ba74-9bcf63c3143a",
   "metadata": {},
   "source": [
    "### Vertically concatenating `DataFrames`\n",
    "\n",
    "Above we saw how to vertically combine two `DataFrames`. More generally, we can combine a `list` of `DataFrames` with `pl.concat`. For clarity, we set the `how=\"vertical\"` argument explicitly this time although it is the default argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afd69b-0370-4175-bef3-cde52ebd6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [df_2000,df_2001],\n",
    "        how=\"vertical\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a524e3d-332e-4462-8027-aff1c962e2da",
   "metadata": {},
   "source": [
    "When we do `pl.concat` Polars:\n",
    "- does a series of `vstacks` to combine the list of `DataFrames`\n",
    "- then does a `rechunk` to gather all the data together in memory\n",
    "\n",
    "We can stop Polars from doing the `rechunk` by passing the `rechunk=False` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd730b48-64d8-40f8-a7c8-4fa1a6a767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vertical = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_2000,\n",
    "            df_2001\n",
    "        ],\n",
    "        rechunk=False\n",
    "    )\n",
    ")\n",
    "df_vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63221700-69ea-4d25-9edb-b8ac6f435890",
   "metadata": {},
   "source": [
    "### Handling different dtypes in vertical concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04bc38-2127-4619-81d5-f8d4b8bcf3c6",
   "metadata": {},
   "source": [
    "Polars expects the column names and dtypes to match when doing vertical concatenation.\n",
    "\n",
    "To illustrate some approaches for handling differences in types we create an alternative `df_2001` where the `quantity` column is 64-bit float instead of 64-bit integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d4f5d-d4b4-4db2-bcef-eb9b078f4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2001_float= (\n",
    "    df_2001\n",
    "    .with_columns(\n",
    "        pl.col(\"quantity\").cast(pl.Float64)\n",
    "    )\n",
    ")\n",
    "df_2001_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f3336-0f90-4315-9d76-6c9bc629123c",
   "metadata": {},
   "source": [
    "When the dtypes do not match we may have to manage this by doing an explicit `cast` of the column types.\n",
    "\n",
    "In this example we cast the `quantity` column back to `pl.Int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca5a38-5ece-48c2-b288-69f93b2c6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_2000,\n",
    "            df_2001_float.with_columns(\n",
    "                pl.col(\"quantity\").cast(pl.Int64)\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf97e59-f321-4958-b8c2-cd612784a074",
   "metadata": {},
   "source": [
    "However, Polars also has a way of managing certain differences by casting to a \"supertype\". For example, the supertype of `pl.Float64` and `pl.Int64` is `pl.Float64`.\n",
    "\n",
    "We can do a vertical concatenation using supertypes where necessary by specifying the `how` method as `vertical_relaxed` instead of `vertical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52051ad4-d2d5-4566-a707-85d22a140a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_2000,\n",
    "            df_2001_float\n",
    "        ],\n",
    "        how=\"vertical_relaxed\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8693d08-2ac3-40c2-bb06-041ba7e7ae6c",
   "metadata": {},
   "source": [
    "\n",
    "## Horizontal concatenation\n",
    "We can horizontally concatenate `DataFrames` that have:\n",
    "- the same number of rows and\n",
    "- different column names\n",
    "\n",
    "For horizontal concatenation we create another `DataFrame` that has more details about each of the trades in 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c055668-f8f4-42c3-93da-849951a9cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000_details = pl.DataFrame(\n",
    "    [\n",
    "        {\"item\":\"Clothes\",\"value\":10},\n",
    "        {\"item\":\"Machinery\",\"value\":100},\n",
    "    ]\n",
    " )\n",
    "df_2000_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee013d61-3007-46e1-a5c6-8736d0df8a71",
   "metadata": {},
   "source": [
    "### `hstack`\n",
    "\n",
    "We can combine two `DataFrames` horizontally with `hstack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506065c-d04d-4456-a5b9-5bc9bfac48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_2000\n",
    "    .hstack(\n",
    "        df_2000_details\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b84fd-778e-4b9b-a6f5-db6ba7a288b7",
   "metadata": {},
   "source": [
    "This operation is *not* in-place unless we pass `in-place=True`.\n",
    "\n",
    "We can also pass a `list` of `Series` inside `hstack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21918570-0780-4490-969f-00e9686d135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_2000\n",
    "    .hstack(\n",
    "        [\n",
    "            df_2000_details[\"item\"],\n",
    "            df_2000_details[\"value\"]\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8682a-fbfd-44ed-b9f7-42d88aea4792",
   "metadata": {},
   "source": [
    "\n",
    "### Horizontal concatenation\n",
    "We can also use `pl.concat` for horizontal concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f875d-9109-44eb-9347-940f1f351e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_2000,\n",
    "            df_2000_details\n",
    "        ]\n",
    "        ,\n",
    "        how=\"horizontal\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e1577-07cf-4c8b-9f7d-5a2fd5c53b94",
   "metadata": {},
   "source": [
    "## Diagonal concatenation\n",
    "\n",
    "We are now looking at new trade records for 2000 and 2001 between China and the USA.\n",
    "\n",
    "In 2000 the schema of the trade records is the same as we saw above with: \n",
    "- `year`\n",
    "- `exporter` and \n",
    "- `importer`\n",
    "\n",
    "However, in 2001 the schema also includes:\n",
    "- `item` and \n",
    "- `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7b1ae-7637-4622-b17a-6e56f921994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = pl.DataFrame(\n",
    "    [\n",
    "        {\"year\":2000,\"exporter\":\"China\",\"importer\":\"USA\",\"quantity\":0},\n",
    "        {\"year\":2000,\"exporter\":\"China\",\"importer\":\"USA\",\"quantity\":1},\n",
    "    ]\n",
    ")\n",
    "df_2001 = pl.DataFrame(\n",
    "    [\n",
    "        {\"year\":2001,\"exporter\":\"China\",\"importer\":\"USA\",\"quantity\":2,\"item\":\"Clothes\",\"value\":10},\n",
    "        {\"year\":2001,\"exporter\":\"China\",\"importer\":\"USA\",\"quantity\":3,\"item\":\"Machinery\",\"value\":100},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8a458-8411-49b4-a0d5-658185cdc378",
   "metadata": {},
   "source": [
    "We want to combine these records into a single `DataFrame`. As the column names are not the same we cannot do a vertical concatenation.\n",
    "\n",
    "Instead we can do a diagonal concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5a31f-27a6-4c73-9f56-696d2792ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            df_2000,\n",
    "            df_2001\n",
    "        ],\n",
    "        how=\"diagonal\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c78268-f2c7-4811-8757-965c9d740a13",
   "metadata": {},
   "source": [
    "This diagonal concatenation is a vertical concatenation for the column names that match but with `null` values where a column is not present in one of the `DataFrames`.\n",
    "\n",
    "We can also do `diagonal_relaxed` where we use supertypes for columns where necessary and possible\n",
    "\n",
    "Diagonal concatenation can be a quick way to work with multiple CSVs or other files where:\n",
    "- the columns are not the same in all files\n",
    "- the order of the columns is not the same in all files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada44ca2-1b80-404e-bee4-bc8b8899b1bb",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d1e51-245c-4d51-a87d-ced06d520c67",
   "metadata": {},
   "source": [
    "You are given the following data from the sales of a bike shop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae297590-3812-4a7e-9cdd-79d6ec91cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_2000 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"quantity\":100},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"quantity\":300},\n",
    "]\n",
    "sales_2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1a9f9-e8f6-4eda-ac39-5c64f4e76b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_2001 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"quantity\":100.0},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"quantity\":300},\n",
    "]\n",
    "sales_2001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253d480c-5735-4a56-a71d-5229bae1f0c2",
   "metadata": {},
   "source": [
    "Combine the 2000 and 2001 data into a single `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174673dd-7eb8-4411-872a-bceed377100e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94679f75-9a09-4ed8-a7a6-347e9eb9f74b",
   "metadata": {},
   "source": [
    "Now add a third year of data to the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e15192-8c8f-4547-a944-61b4c5a4a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_2002 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"type\":\"Hybrid\",\"quantity\":100},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"type\":\"Gravel\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"type\":\"Hybrid\",\"quantity\":300},\n",
    "]\n",
    "sales_2002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538f018-4b73-411b-8393-884e70bc2945",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "In the lecture on quantiles in the Statistics section we learned how to calculate quantiles.\n",
    "\n",
    "In this exercise we will combine multiple quantiles into a single `DataFrame`.\n",
    "\n",
    "As a reminder, this is how we calculate a single quantile on the floating point columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b7243-ab8e-4537-aecb-d44e5a70f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\"\n",
    "df = pl.read_csv(csv_file)\n",
    "q = 0.25\n",
    "(\n",
    "    df\n",
    "    .select(\n",
    "        pl.col(pl.Float64).quantile(q)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefcf20-b019-4ce7-92ce-4701c8c52465",
   "metadata": {},
   "source": [
    "We want to produce a `DataFrame` that has:\n",
    "- the 0.25,0.5 and 0.75 percentiles of the floating point columns on separate rows\n",
    "- a column called `percentiles` to show the percentile for each row \n",
    "\n",
    "Create this `DataFrame` using vertical concatenation.\n",
    "\n",
    "Begin by iterating over the list `quantiles`.\n",
    "\n",
    "On each iteration calculate the quantile for the `Age` and `Fare` columns.\n",
    "\n",
    "Append this output to the list `dfList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a897cc7-8e42-4685-82ac-6dd650f04bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\"\n",
    "df = pl.read_csv(csv_file)\n",
    "quantiles = [0.25,0.5,0.75]\n",
    "dfList = []\n",
    "<blank>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da4a90-a7c1-4676-b337-2147908a4861",
   "metadata": {},
   "source": [
    "Repeat this operation but this time on each iteration add a column called `percentile` that captures the percentile on that iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04657e-1777-4f4a-bae3-f52ee78df3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d55511-16fd-44cd-b900-892154d84a9c",
   "metadata": {},
   "source": [
    "Concatenate the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9cbc6-4450-43e2-998e-6116d38ccc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6102a7-de80-4bdf-8d48-66adbbb92422",
   "metadata": {},
   "source": [
    "## Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab58fd-6867-4978-b074-c0fdc3d353e2",
   "metadata": {},
   "source": [
    "### Solution to Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf19b60-89bb-4062-a7cd-2bd8d43802f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_2000 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"quantity\":100},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"quantity\":300},\n",
    "]\n",
    "sales_2001 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"quantity\":100.0},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"quantity\":300},\n",
    "]\n",
    "\n",
    "sales_2000_df = pl.DataFrame(sales_2000)\n",
    "sales_2001_df = pl.DataFrame(sales_2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deced667-33d3-4b7b-9dde-79e0e64ec91f",
   "metadata": {},
   "source": [
    "Combine the full set of data into a single `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cebde-0592-49c8-9de2-1dcda7959c6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            sales_2000_df,\n",
    "            sales_2001_df\n",
    "        ],\n",
    "        how=\"vertical_relaxed\"\n",
    "    )\n",
    ")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fae94-6fa0-40b6-a812-996fc88c3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_2002 = [\n",
    "    {\"make\":\"Giant\",\"model\":\"Roam\",\"type\":\"Hybrid\",\"quantity\":100},\n",
    "    {\"make\":\"Giant\",\"model\":\"Contend\",\"type\":\"Gravel\",\"quantity\":200},\n",
    "    {\"make\":\"Trek\",\"model\":\"FX\",\"type\":\"Hybrid\",\"quantity\":300},\n",
    "]\n",
    "sales_2002_df = pl.DataFrame(sales_2002)\n",
    "sales_2002_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40bd6c-a8a7-4a6f-ae30-00bea4b0bf32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            sales_2000_df,\n",
    "            sales_2001_df,\n",
    "            sales_2002_df\n",
    "        ],\n",
    "        how=\"diagonal_relaxed\"\n",
    "    )\n",
    ")           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84868029-daf6-4b3d-8b00-9377a99c35d7",
   "metadata": {},
   "source": [
    "### Solution to Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1259f4d-dbb5-4685-a1b4-c7713970c976",
   "metadata": {},
   "source": [
    "Begin by iterating over the list `quantiles`.\n",
    "\n",
    "On each iteration calculate the quantile for the `Age` and `Fare` columns.\n",
    "\n",
    "Append this output to the list `dfList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb374fe2-cc43-48fc-9319-cad685e293b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\"\n",
    "df = pl.read_csv(csv_file)\n",
    "quantiles = [0.25,0.5,0.75]\n",
    "dfList = []\n",
    "for q in quantiles:\n",
    "    dfList.append(\n",
    "        df\n",
    "        .select(\n",
    "            pl.col(pl.Float64).quantile(q)\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0595a-1d17-4d55-af5c-3dd981025909",
   "metadata": {},
   "source": [
    "Repeat this operation but this time on each iteration add a column called `percentile` that captures the percentile on that iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ae7d9-439d-49c3-af5f-73c608850970",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\"\n",
    "df = pl.read_csv(csv_file)\n",
    "quantiles = [0.25,0.5,0.75]\n",
    "dfList = []\n",
    "for q in quantiles:\n",
    "    dfList.append(\n",
    "        df\n",
    "        .select(\n",
    "            pl.col(pl.Float64).quantile(q)\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.lit(q).alias(\"percentiles\")\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf23c1-c48d-4d56-a78b-db5bb3de48f3",
   "metadata": {},
   "source": [
    "Concatenate the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365072a0-dfbd-4263-8d6f-238d6a1c984e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\"\n",
    "df = pl.read_csv(csv_file)\n",
    "quantiles = [0.25,0.5,0.75]\n",
    "dfList = []\n",
    "for q in quantiles:\n",
    "    dfList.append(\n",
    "        df\n",
    "        .select(\n",
    "            pl.col(pl.Float64).quantile(q)\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.lit(q).alias(\"percentiles\")\n",
    "        )\n",
    ")\n",
    "pl.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21117a-4c7c-4609-a104-1b6e7b410049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
